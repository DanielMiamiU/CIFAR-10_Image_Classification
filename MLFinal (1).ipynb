{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaObXcfCIOdQ",
        "outputId": "a1866ba4-3b5a-4420-c6e0-b9beb15a22c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.526412\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.997034\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.675990\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.535159\n",
            "\n",
            "Test set: Average loss: -2.3401, Accuracy: 4816/10000 (48%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.558187\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.366179\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.357726\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.517596\n",
            "\n",
            "Test set: Average loss: -3.0968, Accuracy: 5507/10000 (55%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.384630\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.158962\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.170381\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.292987\n",
            "\n",
            "Test set: Average loss: -3.7316, Accuracy: 6201/10000 (62%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.355726\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.121731\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.075020\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 0.999249\n",
            "\n",
            "Test set: Average loss: -4.3337, Accuracy: 6699/10000 (67%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.011910\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.118445\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.120014\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 1.011300\n",
            "\n",
            "Test set: Average loss: -4.7348, Accuracy: 7021/10000 (70%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.832883\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.844314\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.815994\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.968460\n",
            "\n",
            "Test set: Average loss: -5.1358, Accuracy: 7124/10000 (71%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.811207\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.807203\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.965054\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.817369\n",
            "\n",
            "Test set: Average loss: -5.3911, Accuracy: 7399/10000 (74%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.677537\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.680629\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.649595\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.850345\n",
            "\n",
            "Test set: Average loss: -5.8079, Accuracy: 7586/10000 (76%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.738954\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.698415\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.789726\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.676682\n",
            "\n",
            "Test set: Average loss: -5.8380, Accuracy: 7727/10000 (77%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.695507\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.738987\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.783830\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.673105\n",
            "\n",
            "Test set: Average loss: -6.0169, Accuracy: 7619/10000 (76%)\n",
            "\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.600580\n",
            "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.549181\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.869373\n",
            "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.588090\n",
            "\n",
            "Test set: Average loss: -6.4498, Accuracy: 7941/10000 (79%)\n",
            "\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.885506\n",
            "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.611351\n",
            "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.729353\n",
            "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.668617\n",
            "\n",
            "Test set: Average loss: -6.6465, Accuracy: 7965/10000 (80%)\n",
            "\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.605304\n",
            "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.648334\n",
            "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.725358\n",
            "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.643902\n",
            "\n",
            "Test set: Average loss: -6.7353, Accuracy: 7954/10000 (80%)\n",
            "\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.573397\n",
            "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.575920\n",
            "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.362155\n",
            "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.693578\n",
            "\n",
            "Test set: Average loss: -6.9401, Accuracy: 8102/10000 (81%)\n",
            "\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.449251\n",
            "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.540670\n",
            "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.677058\n",
            "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.533614\n",
            "\n",
            "Test set: Average loss: -6.9398, Accuracy: 8142/10000 (81%)\n",
            "\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.587903\n",
            "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.471136\n",
            "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.468264\n",
            "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.524669\n",
            "\n",
            "Test set: Average loss: -7.1779, Accuracy: 8160/10000 (82%)\n",
            "\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.597361\n",
            "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.497190\n",
            "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.556057\n",
            "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.405427\n",
            "\n",
            "Test set: Average loss: -7.3159, Accuracy: 8259/10000 (83%)\n",
            "\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.661425\n",
            "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.435638\n",
            "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.333813\n",
            "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.587774\n",
            "\n",
            "Test set: Average loss: -7.3127, Accuracy: 8231/10000 (82%)\n",
            "\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.564256\n",
            "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.427405\n",
            "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.521977\n",
            "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.539130\n",
            "\n",
            "Test set: Average loss: -7.5984, Accuracy: 8312/10000 (83%)\n",
            "\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.490365\n",
            "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.414869\n",
            "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.485720\n",
            "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.407773\n",
            "\n",
            "Test set: Average loss: -7.6304, Accuracy: 8303/10000 (83%)\n",
            "\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.389173\n",
            "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.569988\n",
            "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.434619\n",
            "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.521812\n",
            "\n",
            "Test set: Average loss: -7.9634, Accuracy: 8416/10000 (84%)\n",
            "\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.385335\n",
            "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.530149\n",
            "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.500049\n",
            "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.422723\n",
            "\n",
            "Test set: Average loss: -7.7179, Accuracy: 8354/10000 (84%)\n",
            "\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.460906\n",
            "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.451424\n",
            "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.506835\n",
            "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.371961\n",
            "\n",
            "Test set: Average loss: -7.8773, Accuracy: 8364/10000 (84%)\n",
            "\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.535067\n",
            "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.319049\n",
            "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.364682\n",
            "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.496927\n",
            "\n",
            "Test set: Average loss: -8.1103, Accuracy: 8358/10000 (84%)\n",
            "\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.322693\n",
            "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.356533\n",
            "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.477718\n",
            "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.364967\n",
            "\n",
            "Test set: Average loss: -8.1808, Accuracy: 8404/10000 (84%)\n",
            "\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.423015\n",
            "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.513806\n",
            "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.365212\n",
            "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.471734\n",
            "\n",
            "Test set: Average loss: -8.4173, Accuracy: 8487/10000 (85%)\n",
            "\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.375239\n",
            "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.409387\n",
            "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.352109\n",
            "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.461215\n",
            "\n",
            "Test set: Average loss: -8.5096, Accuracy: 8509/10000 (85%)\n",
            "\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.353967\n",
            "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.377502\n",
            "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.427905\n",
            "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.339593\n",
            "\n",
            "Test set: Average loss: -8.6153, Accuracy: 8490/10000 (85%)\n",
            "\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.451641\n",
            "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.344471\n",
            "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.336750\n",
            "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.666069\n",
            "\n",
            "Test set: Average loss: -8.6169, Accuracy: 8537/10000 (85%)\n",
            "\n",
            "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.387783\n",
            "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.395136\n",
            "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.340076\n",
            "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.419407\n",
            "\n",
            "Test set: Average loss: -8.5971, Accuracy: 8501/10000 (85%)\n",
            "\n",
            "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.389838\n",
            "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.432957\n",
            "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.378012\n",
            "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.234943\n",
            "\n",
            "Test set: Average loss: -8.6407, Accuracy: 8486/10000 (85%)\n",
            "\n",
            "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.522107\n",
            "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.383240\n",
            "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.325845\n",
            "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.325828\n",
            "\n",
            "Test set: Average loss: -8.8506, Accuracy: 8570/10000 (86%)\n",
            "\n",
            "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.336517\n",
            "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.342511\n",
            "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.343077\n",
            "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.375446\n",
            "\n",
            "Test set: Average loss: -8.7806, Accuracy: 8506/10000 (85%)\n",
            "\n",
            "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.360109\n",
            "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.411354\n",
            "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.339744\n",
            "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.314243\n",
            "\n",
            "Test set: Average loss: -8.9558, Accuracy: 8533/10000 (85%)\n",
            "\n",
            "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.317641\n",
            "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.335019\n",
            "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.409193\n",
            "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.308168\n",
            "\n",
            "Test set: Average loss: -9.1329, Accuracy: 8600/10000 (86%)\n",
            "\n",
            "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.393083\n",
            "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.320426\n",
            "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.437254\n",
            "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.239605\n",
            "\n",
            "Test set: Average loss: -9.2641, Accuracy: 8653/10000 (87%)\n",
            "\n",
            "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.226307\n",
            "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.318954\n",
            "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.325721\n",
            "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.390133\n",
            "\n",
            "Test set: Average loss: -9.0390, Accuracy: 8476/10000 (85%)\n",
            "\n",
            "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.374065\n",
            "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.494946\n",
            "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.387109\n",
            "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.277262\n",
            "\n",
            "Test set: Average loss: -9.3088, Accuracy: 8563/10000 (86%)\n",
            "\n",
            "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.318620\n",
            "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.290430\n",
            "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.324536\n",
            "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.392452\n",
            "\n",
            "Test set: Average loss: -9.3012, Accuracy: 8550/10000 (86%)\n",
            "\n",
            "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.336158\n",
            "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.237712\n",
            "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.313775\n",
            "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.493888\n",
            "\n",
            "Test set: Average loss: -9.4817, Accuracy: 8631/10000 (86%)\n",
            "\n",
            "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.402937\n",
            "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.338605\n",
            "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.302403\n",
            "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.225166\n",
            "\n",
            "Test set: Average loss: -9.1880, Accuracy: 8636/10000 (86%)\n",
            "\n",
            "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.276443\n",
            "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.243040\n",
            "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.314525\n",
            "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.283902\n",
            "\n",
            "Test set: Average loss: -9.4557, Accuracy: 8545/10000 (85%)\n",
            "\n",
            "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.286695\n",
            "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.337931\n",
            "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.320621\n",
            "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.376292\n",
            "\n",
            "Test set: Average loss: -9.5624, Accuracy: 8653/10000 (87%)\n",
            "\n",
            "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.280532\n",
            "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.288481\n",
            "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.224424\n",
            "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.296366\n",
            "\n",
            "Test set: Average loss: -9.6953, Accuracy: 8632/10000 (86%)\n",
            "\n",
            "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.269822\n",
            "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.484291\n",
            "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.298040\n",
            "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.333476\n",
            "\n",
            "Test set: Average loss: -9.5959, Accuracy: 8671/10000 (87%)\n",
            "\n",
            "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.377937\n",
            "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.264724\n",
            "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.344431\n",
            "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.395820\n",
            "\n",
            "Test set: Average loss: -9.6415, Accuracy: 8706/10000 (87%)\n",
            "\n",
            "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.283005\n",
            "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.181707\n",
            "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.313034\n",
            "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.223396\n",
            "\n",
            "Test set: Average loss: -9.7957, Accuracy: 8667/10000 (87%)\n",
            "\n",
            "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.215428\n",
            "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.204217\n",
            "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.364584\n",
            "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.162829\n",
            "\n",
            "Test set: Average loss: -10.0263, Accuracy: 8691/10000 (87%)\n",
            "\n",
            "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.299515\n",
            "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.310834\n",
            "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.179515\n",
            "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.160403\n",
            "\n",
            "Test set: Average loss: -9.9518, Accuracy: 8629/10000 (86%)\n",
            "\n",
            "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.180946\n",
            "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.260471\n",
            "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.159590\n",
            "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.344873\n",
            "\n",
            "Test set: Average loss: -10.0157, Accuracy: 8709/10000 (87%)\n",
            "\n",
            "Traning and Testing total excution time is: 1301.0463984012604 seconds \n"
          ]
        }
      ],
      "source": [
        "#nn.BatchNorm1d(120)\n",
        "#nn.Dropout(p=0.5)\n",
        "#max_pool2d(out, 2)\n",
        "#.view(out.size(0), -1)\n",
        "#nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
        "#nn.Tanh(),\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import torch  # import the torch library\n",
        "import torch.nn as nn # use the nn module (class)\n",
        "import torch.nn.functional as F    # use the nn module as function\n",
        "import torch.optim as optim # optimization (i.e., SGD, ada,)\n",
        "import torchvision # load the dataset\n",
        "import torchvision.transforms as transforms # adjust the input image\n",
        "import time # check the processing overhead\n",
        "\n",
        "# Preparing for Data\n",
        "print('==> Preparing data..')\n",
        "\n",
        "# Training Data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    #transforms.Resize((64,64)),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "# Testing Data preparation\n",
        "transform_test = transforms.Compose([\n",
        "    #transforms.Resize((64,64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "# total number of classes\n",
        "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Define the class for LeNet\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):# will be called when you create an object\n",
        "        super(LeNet, self).__init__()\n",
        "        ############################\n",
        "        #### Put your code here ####\n",
        "        ############################\n",
        "        self.c1 = nn.Conv2d(3,16,11,stride=1, padding=5)\n",
        "        self.b1 = nn.BatchNorm2d(16)\n",
        "        self.c2 = nn.Conv2d(16,32,7,stride=1, padding=3)\n",
        "        self.b2 = nn.BatchNorm2d(32)\n",
        "        self.c3 = nn.Conv2d(32,64,5,1, padding=2)\n",
        "        self.b3 = nn.BatchNorm2d(64)\n",
        "        self.c4 = nn.Conv2d(64,64,5,1, padding=0)\n",
        "        self.b4 = nn.BatchNorm2d(64)\n",
        "        self.c5 = nn.Conv2d(64,64,5,1, padding=0)\n",
        "        self.b5 = nn.BatchNorm2d(64)\n",
        "        self.c6 = nn.Conv2d(64,320,5,1, padding=0)\n",
        "        self.b6 = nn.BatchNorm2d(320)\n",
        "\n",
        "        self.F1 = nn.Linear(320, 320)\n",
        "        self.F2 = nn.Linear(320, 10)\n",
        "        self.batchNorm1 = nn.BatchNorm1d(320)\n",
        "        self.batchNorm2 = nn.BatchNorm1d(10)\n",
        "        self.dropout = nn.Dropout(.5)\n",
        "        self.MyRelu=nn.ReLU()\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x=self.c1(x)\n",
        "        x=self.b1(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c2(x)\n",
        "        x=self.b2(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c3(x)\n",
        "        x=self.b3(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c4(x)\n",
        "        x=self.b4(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c5(nn.functional.max_pool2d(x,kernel_size=2,stride=2))\n",
        "        x=self.b5(x)\n",
        "        x=self.MyRelu(x)\n",
        "\n",
        "        x=self.c6(nn.functional.max_pool2d(x,kernel_size=2,stride=2))\n",
        "        x=self.b6(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=torch.flatten(x, 1)\n",
        "\n",
        "        x=self.F1(x)\n",
        "        x=self.batchNorm1(x)\n",
        "        x=self.activation(x)\n",
        "        x=self.dropout(x)\n",
        "        x=self.F2(x)\n",
        "        x=self.batchNorm2(x)\n",
        "        x=self.activation(x)\n",
        "        out = x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() # set the model into training model (evaluation model in the testing)\n",
        "    count = 0\n",
        "\n",
        "    loss_Fn=nn.CrossEntropyLoss()\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        out=model(data)\n",
        "        loss=loss_Fn(out,target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test( model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def main():\n",
        "    time0 = time.time()\n",
        "    # Training settings\n",
        "    batch_size = 32\n",
        "    epochs = 50\n",
        "    lr = 0.01\n",
        "    no_cuda = False\n",
        "    save_model = False\n",
        "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "    torch.manual_seed(100)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
        "\n",
        "    model = LeNet().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum = .9, weight_decay=1e-5)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train( model, device, train_loader, optimizer, epoch)\n",
        "        test( model, device, test_loader)\n",
        "\n",
        "    if (save_model):\n",
        "        torch.save(model.state_dict(),\"cifar_lenet.pt\")\n",
        "    time1 = time.time()\n",
        "    print ('Traning and Testing total excution time is: %s seconds ' % (time1-time0))\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}