{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MaObXcfCIOdQ",
        "outputId": "c52ceff2-67c2-45c5-aa76-cdca771700ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==> Preparing data..\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.509631\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tLoss: 1.862492\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tLoss: 1.684059\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tLoss: 1.706787\n",
            "\n",
            "Test set: Average loss: -2.1082, Accuracy: 4682/10000 (47%)\n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.612867\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tLoss: 1.593979\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tLoss: 1.374303\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tLoss: 1.431286\n",
            "\n",
            "Test set: Average loss: -2.9261, Accuracy: 5236/10000 (52%)\n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.350148\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tLoss: 1.367700\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tLoss: 1.261690\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tLoss: 1.156933\n",
            "\n",
            "Test set: Average loss: -3.5369, Accuracy: 5815/10000 (58%)\n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.126280\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tLoss: 1.176665\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tLoss: 1.118999\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tLoss: 1.099587\n",
            "\n",
            "Test set: Average loss: -4.2289, Accuracy: 6544/10000 (65%)\n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tLoss: 0.999071\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tLoss: 1.053985\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tLoss: 1.067915\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tLoss: 0.953378\n",
            "\n",
            "Test set: Average loss: -4.6826, Accuracy: 6897/10000 (69%)\n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tLoss: 0.936238\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tLoss: 0.855036\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tLoss: 0.954872\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tLoss: 0.860233\n",
            "\n",
            "Test set: Average loss: -5.0068, Accuracy: 7091/10000 (71%)\n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.899674\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tLoss: 0.969540\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tLoss: 0.948008\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tLoss: 0.949605\n",
            "\n",
            "Test set: Average loss: -5.1474, Accuracy: 7306/10000 (73%)\n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tLoss: 0.859239\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tLoss: 0.862893\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tLoss: 0.856926\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tLoss: 0.963447\n",
            "\n",
            "Test set: Average loss: -5.4970, Accuracy: 7464/10000 (75%)\n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.925143\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tLoss: 0.768783\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tLoss: 0.781522\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tLoss: 0.695396\n",
            "\n",
            "Test set: Average loss: -5.7014, Accuracy: 7493/10000 (75%)\n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.788017\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tLoss: 0.627715\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tLoss: 0.838177\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tLoss: 0.747345\n",
            "\n",
            "Test set: Average loss: -5.9256, Accuracy: 7666/10000 (77%)\n",
            "\n",
            "Train Epoch: 11 [0/50000 (0%)]\tLoss: 0.716683\n",
            "Train Epoch: 11 [12800/50000 (26%)]\tLoss: 0.731975\n",
            "Train Epoch: 11 [25600/50000 (51%)]\tLoss: 0.623653\n",
            "Train Epoch: 11 [38400/50000 (77%)]\tLoss: 0.638454\n",
            "\n",
            "Test set: Average loss: -6.2523, Accuracy: 7862/10000 (79%)\n",
            "\n",
            "Train Epoch: 12 [0/50000 (0%)]\tLoss: 0.567566\n",
            "Train Epoch: 12 [12800/50000 (26%)]\tLoss: 0.698701\n",
            "Train Epoch: 12 [25600/50000 (51%)]\tLoss: 0.560973\n",
            "Train Epoch: 12 [38400/50000 (77%)]\tLoss: 0.664891\n",
            "\n",
            "Test set: Average loss: -6.2015, Accuracy: 7664/10000 (77%)\n",
            "\n",
            "Train Epoch: 13 [0/50000 (0%)]\tLoss: 0.692406\n",
            "Train Epoch: 13 [12800/50000 (26%)]\tLoss: 0.665470\n",
            "Train Epoch: 13 [25600/50000 (51%)]\tLoss: 0.485514\n",
            "Train Epoch: 13 [38400/50000 (77%)]\tLoss: 0.493363\n",
            "\n",
            "Test set: Average loss: -6.5072, Accuracy: 7951/10000 (80%)\n",
            "\n",
            "Train Epoch: 14 [0/50000 (0%)]\tLoss: 0.588470\n",
            "Train Epoch: 14 [12800/50000 (26%)]\tLoss: 0.737125\n",
            "Train Epoch: 14 [25600/50000 (51%)]\tLoss: 0.554229\n",
            "Train Epoch: 14 [38400/50000 (77%)]\tLoss: 0.783268\n",
            "\n",
            "Test set: Average loss: -6.7260, Accuracy: 8034/10000 (80%)\n",
            "\n",
            "Train Epoch: 15 [0/50000 (0%)]\tLoss: 0.686916\n",
            "Train Epoch: 15 [12800/50000 (26%)]\tLoss: 0.747344\n",
            "Train Epoch: 15 [25600/50000 (51%)]\tLoss: 0.668311\n",
            "Train Epoch: 15 [38400/50000 (77%)]\tLoss: 0.501945\n",
            "\n",
            "Test set: Average loss: -6.7318, Accuracy: 8057/10000 (81%)\n",
            "\n",
            "Train Epoch: 16 [0/50000 (0%)]\tLoss: 0.548302\n",
            "Train Epoch: 16 [12800/50000 (26%)]\tLoss: 0.473445\n",
            "Train Epoch: 16 [25600/50000 (51%)]\tLoss: 0.594830\n",
            "Train Epoch: 16 [38400/50000 (77%)]\tLoss: 0.562692\n",
            "\n",
            "Test set: Average loss: -6.8478, Accuracy: 8094/10000 (81%)\n",
            "\n",
            "Train Epoch: 17 [0/50000 (0%)]\tLoss: 0.405012\n",
            "Train Epoch: 17 [12800/50000 (26%)]\tLoss: 0.695373\n",
            "Train Epoch: 17 [25600/50000 (51%)]\tLoss: 0.494693\n",
            "Train Epoch: 17 [38400/50000 (77%)]\tLoss: 0.464376\n",
            "\n",
            "Test set: Average loss: -7.0632, Accuracy: 8116/10000 (81%)\n",
            "\n",
            "Train Epoch: 18 [0/50000 (0%)]\tLoss: 0.499297\n",
            "Train Epoch: 18 [12800/50000 (26%)]\tLoss: 0.618066\n",
            "Train Epoch: 18 [25600/50000 (51%)]\tLoss: 0.486433\n",
            "Train Epoch: 18 [38400/50000 (77%)]\tLoss: 0.692451\n",
            "\n",
            "Test set: Average loss: -6.8325, Accuracy: 7938/10000 (79%)\n",
            "\n",
            "Train Epoch: 19 [0/50000 (0%)]\tLoss: 0.592119\n",
            "Train Epoch: 19 [12800/50000 (26%)]\tLoss: 0.374770\n",
            "Train Epoch: 19 [25600/50000 (51%)]\tLoss: 0.793905\n",
            "Train Epoch: 19 [38400/50000 (77%)]\tLoss: 0.455876\n",
            "\n",
            "Test set: Average loss: -7.2705, Accuracy: 8108/10000 (81%)\n",
            "\n",
            "Train Epoch: 20 [0/50000 (0%)]\tLoss: 0.500243\n",
            "Train Epoch: 20 [12800/50000 (26%)]\tLoss: 0.537282\n",
            "Train Epoch: 20 [25600/50000 (51%)]\tLoss: 0.403264\n",
            "Train Epoch: 20 [38400/50000 (77%)]\tLoss: 0.411221\n",
            "\n",
            "Test set: Average loss: -7.4242, Accuracy: 8320/10000 (83%)\n",
            "\n",
            "Train Epoch: 21 [0/50000 (0%)]\tLoss: 0.468298\n",
            "Train Epoch: 21 [12800/50000 (26%)]\tLoss: 0.487061\n",
            "Train Epoch: 21 [25600/50000 (51%)]\tLoss: 0.419985\n",
            "Train Epoch: 21 [38400/50000 (77%)]\tLoss: 0.550446\n",
            "\n",
            "Test set: Average loss: -7.4973, Accuracy: 8153/10000 (82%)\n",
            "\n",
            "Train Epoch: 22 [0/50000 (0%)]\tLoss: 0.514196\n",
            "Train Epoch: 22 [12800/50000 (26%)]\tLoss: 0.443056\n",
            "Train Epoch: 22 [25600/50000 (51%)]\tLoss: 0.529793\n",
            "Train Epoch: 22 [38400/50000 (77%)]\tLoss: 0.455137\n",
            "\n",
            "Test set: Average loss: -7.6591, Accuracy: 8272/10000 (83%)\n",
            "\n",
            "Train Epoch: 23 [0/50000 (0%)]\tLoss: 0.510076\n",
            "Train Epoch: 23 [12800/50000 (26%)]\tLoss: 0.413958\n",
            "Train Epoch: 23 [25600/50000 (51%)]\tLoss: 0.428767\n",
            "Train Epoch: 23 [38400/50000 (77%)]\tLoss: 0.593419\n",
            "\n",
            "Test set: Average loss: -7.2672, Accuracy: 8007/10000 (80%)\n",
            "\n",
            "Train Epoch: 24 [0/50000 (0%)]\tLoss: 0.482929\n",
            "Train Epoch: 24 [12800/50000 (26%)]\tLoss: 0.575848\n",
            "Train Epoch: 24 [25600/50000 (51%)]\tLoss: 0.640677\n",
            "Train Epoch: 24 [38400/50000 (77%)]\tLoss: 0.390314\n",
            "\n",
            "Test set: Average loss: -7.7488, Accuracy: 8356/10000 (84%)\n",
            "\n",
            "Train Epoch: 25 [0/50000 (0%)]\tLoss: 0.464920\n",
            "Train Epoch: 25 [12800/50000 (26%)]\tLoss: 0.445766\n",
            "Train Epoch: 25 [25600/50000 (51%)]\tLoss: 0.312880\n",
            "Train Epoch: 25 [38400/50000 (77%)]\tLoss: 0.533206\n",
            "\n",
            "Test set: Average loss: -7.9530, Accuracy: 8315/10000 (83%)\n",
            "\n",
            "Train Epoch: 26 [0/50000 (0%)]\tLoss: 0.454393\n",
            "Train Epoch: 26 [12800/50000 (26%)]\tLoss: 0.403928\n",
            "Train Epoch: 26 [25600/50000 (51%)]\tLoss: 0.427699\n",
            "Train Epoch: 26 [38400/50000 (77%)]\tLoss: 0.414644\n",
            "\n",
            "Test set: Average loss: -7.8884, Accuracy: 8196/10000 (82%)\n",
            "\n",
            "Train Epoch: 27 [0/50000 (0%)]\tLoss: 0.285435\n",
            "Train Epoch: 27 [12800/50000 (26%)]\tLoss: 0.407586\n",
            "Train Epoch: 27 [25600/50000 (51%)]\tLoss: 0.352501\n",
            "Train Epoch: 27 [38400/50000 (77%)]\tLoss: 0.522621\n",
            "\n",
            "Test set: Average loss: -8.0174, Accuracy: 8335/10000 (83%)\n",
            "\n",
            "Train Epoch: 28 [0/50000 (0%)]\tLoss: 0.506855\n",
            "Train Epoch: 28 [12800/50000 (26%)]\tLoss: 0.276311\n",
            "Train Epoch: 28 [25600/50000 (51%)]\tLoss: 0.482650\n",
            "Train Epoch: 28 [38400/50000 (77%)]\tLoss: 0.282690\n",
            "\n",
            "Test set: Average loss: -8.0533, Accuracy: 8472/10000 (85%)\n",
            "\n",
            "Train Epoch: 29 [0/50000 (0%)]\tLoss: 0.415007\n",
            "Train Epoch: 29 [12800/50000 (26%)]\tLoss: 0.443370\n",
            "Train Epoch: 29 [25600/50000 (51%)]\tLoss: 0.412013\n",
            "Train Epoch: 29 [38400/50000 (77%)]\tLoss: 0.481755\n",
            "\n",
            "Test set: Average loss: -8.1008, Accuracy: 8508/10000 (85%)\n",
            "\n",
            "Train Epoch: 30 [0/50000 (0%)]\tLoss: 0.417728\n",
            "Train Epoch: 30 [12800/50000 (26%)]\tLoss: 0.463264\n",
            "Train Epoch: 30 [25600/50000 (51%)]\tLoss: 0.392319\n",
            "Train Epoch: 30 [38400/50000 (77%)]\tLoss: 0.520521\n",
            "\n",
            "Test set: Average loss: -8.3617, Accuracy: 8499/10000 (85%)\n",
            "\n",
            "Train Epoch: 31 [0/50000 (0%)]\tLoss: 0.427079\n",
            "Train Epoch: 31 [12800/50000 (26%)]\tLoss: 0.485081\n",
            "Train Epoch: 31 [25600/50000 (51%)]\tLoss: 0.323849\n",
            "Train Epoch: 31 [38400/50000 (77%)]\tLoss: 0.467508\n",
            "\n",
            "Test set: Average loss: -8.3083, Accuracy: 8485/10000 (85%)\n",
            "\n",
            "Train Epoch: 32 [0/50000 (0%)]\tLoss: 0.405719\n",
            "Train Epoch: 32 [12800/50000 (26%)]\tLoss: 0.372326\n",
            "Train Epoch: 32 [25600/50000 (51%)]\tLoss: 0.361948\n",
            "Train Epoch: 32 [38400/50000 (77%)]\tLoss: 0.356014\n",
            "\n",
            "Test set: Average loss: -8.2306, Accuracy: 8449/10000 (84%)\n",
            "\n",
            "Train Epoch: 33 [0/50000 (0%)]\tLoss: 0.288043\n",
            "Train Epoch: 33 [12800/50000 (26%)]\tLoss: 0.355478\n",
            "Train Epoch: 33 [25600/50000 (51%)]\tLoss: 0.397726\n",
            "Train Epoch: 33 [38400/50000 (77%)]\tLoss: 0.338168\n",
            "\n",
            "Test set: Average loss: -8.5451, Accuracy: 8409/10000 (84%)\n",
            "\n",
            "Train Epoch: 34 [0/50000 (0%)]\tLoss: 0.396777\n",
            "Train Epoch: 34 [12800/50000 (26%)]\tLoss: 0.232391\n",
            "Train Epoch: 34 [25600/50000 (51%)]\tLoss: 0.419529\n",
            "Train Epoch: 34 [38400/50000 (77%)]\tLoss: 0.414777\n",
            "\n",
            "Test set: Average loss: -8.5320, Accuracy: 8487/10000 (85%)\n",
            "\n",
            "Train Epoch: 35 [0/50000 (0%)]\tLoss: 0.310313\n",
            "Train Epoch: 35 [12800/50000 (26%)]\tLoss: 0.355313\n",
            "Train Epoch: 35 [25600/50000 (51%)]\tLoss: 0.448274\n",
            "Train Epoch: 35 [38400/50000 (77%)]\tLoss: 0.515821\n",
            "\n",
            "Test set: Average loss: -8.6541, Accuracy: 8507/10000 (85%)\n",
            "\n",
            "Train Epoch: 36 [0/50000 (0%)]\tLoss: 0.526999\n",
            "Train Epoch: 36 [12800/50000 (26%)]\tLoss: 0.213893\n",
            "Train Epoch: 36 [25600/50000 (51%)]\tLoss: 0.318692\n",
            "Train Epoch: 36 [38400/50000 (77%)]\tLoss: 0.405060\n",
            "\n",
            "Test set: Average loss: -8.6272, Accuracy: 8410/10000 (84%)\n",
            "\n",
            "Train Epoch: 37 [0/50000 (0%)]\tLoss: 0.258699\n",
            "Train Epoch: 37 [12800/50000 (26%)]\tLoss: 0.280035\n",
            "Train Epoch: 37 [25600/50000 (51%)]\tLoss: 0.390768\n",
            "Train Epoch: 37 [38400/50000 (77%)]\tLoss: 0.321651\n",
            "\n",
            "Test set: Average loss: -8.7751, Accuracy: 8509/10000 (85%)\n",
            "\n",
            "Train Epoch: 38 [0/50000 (0%)]\tLoss: 0.331455\n",
            "Train Epoch: 38 [12800/50000 (26%)]\tLoss: 0.319590\n",
            "Train Epoch: 38 [25600/50000 (51%)]\tLoss: 0.372081\n",
            "Train Epoch: 38 [38400/50000 (77%)]\tLoss: 0.352476\n",
            "\n",
            "Test set: Average loss: -8.6880, Accuracy: 8450/10000 (84%)\n",
            "\n",
            "Train Epoch: 39 [0/50000 (0%)]\tLoss: 0.428158\n",
            "Train Epoch: 39 [12800/50000 (26%)]\tLoss: 0.373997\n",
            "Train Epoch: 39 [25600/50000 (51%)]\tLoss: 0.303783\n",
            "Train Epoch: 39 [38400/50000 (77%)]\tLoss: 0.379808\n",
            "\n",
            "Test set: Average loss: -8.9298, Accuracy: 8614/10000 (86%)\n",
            "\n",
            "Train Epoch: 40 [0/50000 (0%)]\tLoss: 0.282879\n",
            "Train Epoch: 40 [12800/50000 (26%)]\tLoss: 0.324021\n",
            "Train Epoch: 40 [25600/50000 (51%)]\tLoss: 0.402952\n",
            "Train Epoch: 40 [38400/50000 (77%)]\tLoss: 0.380848\n",
            "\n",
            "Test set: Average loss: -8.8590, Accuracy: 8519/10000 (85%)\n",
            "\n",
            "Train Epoch: 41 [0/50000 (0%)]\tLoss: 0.340803\n",
            "Train Epoch: 41 [12800/50000 (26%)]\tLoss: 0.428298\n",
            "Train Epoch: 41 [25600/50000 (51%)]\tLoss: 0.284862\n",
            "Train Epoch: 41 [38400/50000 (77%)]\tLoss: 0.418662\n",
            "\n",
            "Test set: Average loss: -9.1257, Accuracy: 8539/10000 (85%)\n",
            "\n",
            "Train Epoch: 42 [0/50000 (0%)]\tLoss: 0.484447\n",
            "Train Epoch: 42 [12800/50000 (26%)]\tLoss: 0.309022\n",
            "Train Epoch: 42 [25600/50000 (51%)]\tLoss: 0.476759\n",
            "Train Epoch: 42 [38400/50000 (77%)]\tLoss: 0.313654\n",
            "\n",
            "Test set: Average loss: -9.0559, Accuracy: 8592/10000 (86%)\n",
            "\n",
            "Train Epoch: 43 [0/50000 (0%)]\tLoss: 0.200387\n",
            "Train Epoch: 43 [12800/50000 (26%)]\tLoss: 0.444162\n",
            "Train Epoch: 43 [25600/50000 (51%)]\tLoss: 0.246825\n",
            "Train Epoch: 43 [38400/50000 (77%)]\tLoss: 0.227413\n",
            "\n",
            "Test set: Average loss: -9.1736, Accuracy: 8588/10000 (86%)\n",
            "\n",
            "Train Epoch: 44 [0/50000 (0%)]\tLoss: 0.254643\n",
            "Train Epoch: 44 [12800/50000 (26%)]\tLoss: 0.258496\n",
            "Train Epoch: 44 [25600/50000 (51%)]\tLoss: 0.264957\n",
            "Train Epoch: 44 [38400/50000 (77%)]\tLoss: 0.289203\n",
            "\n",
            "Test set: Average loss: -9.0418, Accuracy: 8650/10000 (86%)\n",
            "\n",
            "Train Epoch: 45 [0/50000 (0%)]\tLoss: 0.453490\n",
            "Train Epoch: 45 [12800/50000 (26%)]\tLoss: 0.166797\n",
            "Train Epoch: 45 [25600/50000 (51%)]\tLoss: 0.528102\n",
            "Train Epoch: 45 [38400/50000 (77%)]\tLoss: 0.335299\n",
            "\n",
            "Test set: Average loss: -9.2617, Accuracy: 8565/10000 (86%)\n",
            "\n",
            "Train Epoch: 46 [0/50000 (0%)]\tLoss: 0.336610\n",
            "Train Epoch: 46 [12800/50000 (26%)]\tLoss: 0.285497\n",
            "Train Epoch: 46 [25600/50000 (51%)]\tLoss: 0.221245\n",
            "Train Epoch: 46 [38400/50000 (77%)]\tLoss: 0.364617\n",
            "\n",
            "Test set: Average loss: -8.9425, Accuracy: 8485/10000 (85%)\n",
            "\n",
            "Train Epoch: 47 [0/50000 (0%)]\tLoss: 0.252105\n",
            "Train Epoch: 47 [12800/50000 (26%)]\tLoss: 0.323706\n",
            "Train Epoch: 47 [25600/50000 (51%)]\tLoss: 0.261694\n",
            "Train Epoch: 47 [38400/50000 (77%)]\tLoss: 0.189035\n",
            "\n",
            "Test set: Average loss: -9.2911, Accuracy: 8476/10000 (85%)\n",
            "\n",
            "Train Epoch: 48 [0/50000 (0%)]\tLoss: 0.241799\n",
            "Train Epoch: 48 [12800/50000 (26%)]\tLoss: 0.374755\n",
            "Train Epoch: 48 [25600/50000 (51%)]\tLoss: 0.315686\n",
            "Train Epoch: 48 [38400/50000 (77%)]\tLoss: 0.382603\n",
            "\n",
            "Test set: Average loss: -9.4803, Accuracy: 8577/10000 (86%)\n",
            "\n",
            "Train Epoch: 49 [0/50000 (0%)]\tLoss: 0.192461\n",
            "Train Epoch: 49 [12800/50000 (26%)]\tLoss: 0.240141\n",
            "Train Epoch: 49 [25600/50000 (51%)]\tLoss: 0.319610\n",
            "Train Epoch: 49 [38400/50000 (77%)]\tLoss: 0.201123\n",
            "\n",
            "Test set: Average loss: -9.3318, Accuracy: 8606/10000 (86%)\n",
            "\n",
            "Train Epoch: 50 [0/50000 (0%)]\tLoss: 0.200824\n",
            "Train Epoch: 50 [12800/50000 (26%)]\tLoss: 0.260044\n",
            "Train Epoch: 50 [25600/50000 (51%)]\tLoss: 0.354727\n",
            "Train Epoch: 50 [38400/50000 (77%)]\tLoss: 0.414915\n",
            "\n",
            "Test set: Average loss: -9.4674, Accuracy: 8639/10000 (86%)\n",
            "\n",
            "Traning and Testing total excution time is: 1417.2634329795837 seconds \n"
          ]
        }
      ],
      "source": [
        "#nn.BatchNorm1d(120)\n",
        "#nn.Dropout(p=0.5)\n",
        "#max_pool2d(out, 2)\n",
        "#.view(out.size(0), -1)\n",
        "#nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5, stride=1),\n",
        "#nn.Tanh(),\n",
        "from __future__ import print_function\n",
        "import torch  # import the torch library\n",
        "import torch.nn as nn # use the nn module (class)\n",
        "import torch.nn.functional as F    # use the nn module as function\n",
        "import torch.optim as optim # optimization (i.e., SGD, ada,)\n",
        "import torchvision # load the dataset\n",
        "import torchvision.transforms as transforms # adjust the input image\n",
        "import time # check the processing overhead\n",
        "\n",
        "# Preparing for Data\n",
        "print('==> Preparing data..')\n",
        "\n",
        "# Training Data augmentation\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "# Testing Data preparation\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "\n",
        "# total number of classes\n",
        "#classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Define the class for LeNet\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):# will be called when you create an object\n",
        "        super(LeNet, self).__init__()\n",
        "        ############################\n",
        "        #### Put your code here ####\n",
        "        ############################\n",
        "        self.c1 = nn.Conv2d(3,16,11,stride=1, padding=5)\n",
        "        self.b1 = nn.BatchNorm2d(16)\n",
        "        self.c2 = nn.Conv2d(16,32,7,stride=1, padding=3)\n",
        "        self.b2 = nn.BatchNorm2d(32)\n",
        "        self.c3 = nn.Conv2d(32,64,5,1, padding=2)\n",
        "        self.b3 = nn.BatchNorm2d(64)\n",
        "        self.c4 = nn.Conv2d(64,64,5,1, padding=0)\n",
        "        self.b4 = nn.BatchNorm2d(64)\n",
        "        self.c5 = nn.Conv2d(64,64,5,1, padding=0)\n",
        "        self.b5 = nn.BatchNorm2d(64)\n",
        "        self.c6 = nn.Conv2d(64,320,5,1, padding=0)\n",
        "\n",
        "        self.F1 = nn.Linear(320, 160)\n",
        "        self.F2 = nn.Linear(160, 10)\n",
        "        self.batchNorm1 = nn.BatchNorm1d(160)\n",
        "        self.batchNorm2 = nn.BatchNorm1d(10)\n",
        "        self.dropout = nn.Dropout(.5)\n",
        "        self.MyRelu=nn.ReLU()\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "\n",
        "\n",
        "        ###########################\n",
        "        #### End of your codes ####\n",
        "        ###########################\n",
        "        # X would be the input data (not the label)\n",
        "    def forward(self, x):  # this function will be called when you run the model\n",
        "        ############################\n",
        "        #### Put your code here ####\n",
        "        ############################\n",
        "        x=self.c1(x)\n",
        "        x=self.b1(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c2(x)\n",
        "        x=self.b2(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c3(x)\n",
        "        x=self.b3(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c4(x)\n",
        "        x=self.b4(x)\n",
        "        x=self.MyRelu(x)\n",
        "        x=self.c5(nn.functional.max_pool2d(x,kernel_size=2,stride=2))\n",
        "        x=self.b5(x)\n",
        "        x=self.MyRelu(x)\n",
        "\n",
        "        x=self.c6(nn.functional.max_pool2d(x,kernel_size=2,stride=2))\n",
        "\n",
        "        x=self.MyRelu(x)\n",
        "        x=torch.flatten(x, 1)\n",
        "\n",
        "        x=self.F1(x)\n",
        "        x=self.batchNorm1(x)\n",
        "        x=self.activation(x)\n",
        "        x=self.dropout(x)\n",
        "        x=self.F2(x)\n",
        "        x=self.batchNorm2(x)\n",
        "        x=self.activation(x)\n",
        "        out = x\n",
        "\n",
        "\n",
        "        ###########################\n",
        "        #### End of your codes ####\n",
        "        ###########################\n",
        "\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train() # set the model into training model (evaluation model in the testing)\n",
        "    count = 0\n",
        "\n",
        "    loss_Fn=nn.CrossEntropyLoss()\n",
        "    #nn.functional.cross_entropy()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      #data is the image\n",
        "      #target is the ground truth\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        ############################\n",
        "        #### Put your code here ####\n",
        "        ############################\n",
        "\n",
        "        out=model(data)\n",
        "        loss=loss_Fn(out,target)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ###########################\n",
        "        #### End of your codes ####\n",
        "        ###########################\n",
        "        if batch_idx % 100 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test( model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "\n",
        "def main():\n",
        "    time0 = time.time()\n",
        "    # Training settings\n",
        "    batch_size = 16\n",
        "    epochs = 50\n",
        "    lr = 0.01\n",
        "    no_cuda = False\n",
        "    save_model = False\n",
        "    use_cuda = not no_cuda and torch.cuda.is_available()\n",
        "    torch.manual_seed(100)\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
        "    testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    test_loader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False)\n",
        "\n",
        "    model = LeNet().to(device)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=.9, weight_decay=1e-5)\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train( model, device, train_loader, optimizer, epoch)\n",
        "        test( model, device, test_loader)\n",
        "\n",
        "    if (save_model):\n",
        "        torch.save(model.state_dict(),\"cifar_lenet.pt\")\n",
        "    time1 = time.time()\n",
        "    print ('Traning and Testing total excution time is: %s seconds ' % (time1-time0))\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}